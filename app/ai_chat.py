"""AI-powered chat handler for the Bitrix imbot.

Combines:
- OpenAI for generating responses
- Product catalog for search / recommendations
- Conversation history from Redis
- FAQ knowledge base
- "Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€" keyword â†’ transfer to live operator
"""
from __future__ import annotations

import logging
import re
from typing import Any, Dict, List, Optional, Tuple

from .llm import LLMError, LLMProvider
from .scraper import ProductCatalog
from .storage import Storage

log = logging.getLogger("app.ai_chat")

# ---------------------------------------------------------------------------
# Markdown stripping â€” Bitrix IM doesn't render Markdown so we remove it
# ---------------------------------------------------------------------------

_RE_BOLD = re.compile(r"\*\*(.+?)\*\*")          # **bold**
_RE_ITALIC_STAR = re.compile(r"\*(.+?)\*")        # *italic*
_RE_ITALIC_UNDER = re.compile(r"(?<!\w)_(.+?)_(?!\w)")  # _italic_
_RE_STRIKE = re.compile(r"~~(.+?)~~")             # ~~strike~~
_RE_INLINE_CODE = re.compile(r"`(.+?)`")          # `code`
_RE_HEADING = re.compile(r"^#{1,6}\s+", re.MULTILINE)   # ### heading
_RE_LINK = re.compile(r"\[([^\]]+)]\(([^)]+)\)")  # [text](url)


def _strip_markdown(text: str) -> str:
    """Remove Markdown formatting that Bitrix IM cannot render."""
    text = _RE_BOLD.sub(r"\1", text)
    text = _RE_ITALIC_STAR.sub(r"\1", text)
    text = _RE_ITALIC_UNDER.sub(r"\1", text)
    text = _RE_STRIKE.sub(r"\1", text)
    text = _RE_INLINE_CODE.sub(r"\1", text)
    text = _RE_HEADING.sub("", text)
    # [text](url) â†’ text (url)  â€” keep the URL visible
    text = _RE_LINK.sub(r"\1 (\2)", text)
    return text


# Maximum history messages to include in the prompt (pairs of user+assistant)
MAX_HISTORY_MESSAGES = 20

# Maximum products to include in search results sent to GPT
MAX_SEARCH_RESULTS_FOR_GPT = 8

# System prompt template
SYSTEM_PROMPT = """Ð¢Ñ‹ â€” AI-ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚-Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð° Ð¼Ð¾Ñ€ÐµÐ¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð² myryba.ru (ÐœÐ¾ÑÐ Ñ‹Ð±Ð°).
Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÑŒ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»ÑÐ¼ Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð¼ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð², Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€Ð°Ñ…, Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸, Ñ†ÐµÐ½Ð°Ñ…, Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐµ Ð¸ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ð¸.

ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:
1. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾, ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÐ¼Ð¾Ð´Ð·Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾.
2. Ð•ÑÐ»Ð¸ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»ÑŒ ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ð¾ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð¼ Ñ‚Ð¾Ð²Ð°Ñ€Ðµ â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· [Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ñƒ], Ð¿Ñ€Ð¸ÐºÑ€ÐµÐ¿Ð»Ñ‘Ð½Ð½Ñ‹Ðµ Ðº ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÑŽ. Ð”Ð°Ð²Ð°Ð¹ Ñ‚Ð¾Ñ‡Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ: Ñ†ÐµÐ½Ð°, Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ, ÑÑÑ‹Ð»ÐºÐ°.
3. Ð•ÑÐ»Ð¸ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½ÐµÐ¾Ð´Ð½Ð¾Ð·Ð½Ð°Ñ‡Ð½Ñ‹Ð¹ â€” Ð·Ð°Ð´Ð°Ð¹ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ.
4. Ð•ÑÐ»Ð¸ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð½ÐµÑ‚ Ð² Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸ â€” Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸ Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸ Ð¸Ð· Ñ‚Ð¾Ð¹ Ð¶Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸.
5. Ð’ÑÐµÐ³Ð´Ð° ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ñ†ÐµÐ½Ñƒ Ð² Ñ€ÑƒÐ±Ð»ÑÑ… Ð¸ ÑÑÑ‹Ð»ÐºÑƒ Ð½Ð° Ñ‚Ð¾Ð²Ð°Ñ€, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ.
6. Ð•ÑÐ»Ð¸ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»ÑŒ Ñ…Ð¾Ñ‡ÐµÑ‚ ÑÐ²ÑÐ·Ð°Ñ‚ÑŒÑÑ Ñ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼ â€” ÑÐºÐ°Ð¶Ð¸, Ñ‡Ñ‚Ð¾ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð¸ÑˆÑŒ Ð½Ð° Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°.
7. ÐÐµ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð½ÐµÑ‚ Ð² ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ðµ. Ð•ÑÐ»Ð¸ Ð½Ðµ Ð½Ð°ÑˆÑ‘Ð» â€” Ñ‚Ð°Ðº Ð¸ ÑÐºÐ°Ð¶Ð¸.
8. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°: Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚. ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Markdown-Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÑƒ (Ð¶Ð¸Ñ€Ð½Ñ‹Ð¹, ÐºÑƒÑ€ÑÐ¸Ð², Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸, ÑÐ¿Ð¸ÑÐºÐ¸ Ñ *, ÑÑÑ‹Ð»ÐºÐ¸ []() Ð¸ Ñ‚.Ð´.) â€” Bitrix IM ÐµÑ‘ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚.

FAQ â€” Ñ‡Ð°ÑÑ‚Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹:
- ÐÐ´Ñ€ÐµÑ: ÐœÐ¾ÑÐºÐ²Ð° (Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð°Ð´Ñ€ÐµÑ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÐ¹Ñ‚Ðµ Ñƒ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð° Ð¸Ð»Ð¸ Ð½Ð° ÑÐ°Ð¹Ñ‚Ðµ myryba.ru)
- Ð ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ð¾ (Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ Ñ‡Ð°ÑÑ‹ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÐ¹Ñ‚Ðµ Ð½Ð° ÑÐ°Ð¹Ñ‚Ðµ)
- Ð”Ð¾ÑÑ‚Ð°Ð²ÐºÐ°: Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ° Ð¿Ð¾ ÐœÐ¾ÑÐºÐ²Ðµ Ð¸ ÐœÐž, Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ð½Ð° ÑÐ°Ð¹Ñ‚Ðµ myryba.ru
- ÐžÐ¿Ð»Ð°Ñ‚Ð°: Ð½Ð°Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ, ÐºÐ°Ñ€Ñ‚Ð°, Ð¾Ð½Ð»Ð°Ð¹Ð½-Ð¾Ð¿Ð»Ð°Ñ‚Ð°
- Ð¥Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ: Ð¼Ð¾Ñ€ÐµÐ¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹ Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð² Ð¼Ð¾Ñ€Ð¾Ð·Ð¸Ð»ÑŒÐ½Ð¾Ð¹ ÐºÐ°Ð¼ÐµÑ€Ðµ Ð¿Ñ€Ð¸ -18Â°C, Ñ€Ð°Ð·Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ðµ â€” Ð² Ñ…Ð¾Ð»Ð¾Ð´Ð¸Ð»ÑŒÐ½Ð¸ÐºÐµ Ð´Ð¾ 24Ñ‡
- Ð¡Ñ€Ð¾Ðº Ð³Ð¾Ð´Ð½Ð¾ÑÑ‚Ð¸: Ð·Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð°, Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ 6-12 Ð¼ÐµÑÑÑ†ÐµÐ² Ð´Ð»Ñ Ð·Ð°Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ñ…, ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ ÑƒÐ¿Ð°ÐºÐ¾Ð²ÐºÑƒ
- Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚: Ð¿Ð¾ Ð·Ð°ÐºÐ¾Ð½Ñƒ Ð¾ Ð·Ð°Ñ‰Ð¸Ñ‚Ðµ Ð¿Ñ€Ð°Ð² Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»ÐµÐ¹, ÑÐ²ÑÐ¶Ð¸Ñ‚ÐµÑÑŒ Ñ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼

Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð²:
{catalog_summary}

ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€Ð°Ñ… Ð¿Ñ€Ð¸Ñ…Ð¾Ð´Ð¸Ñ‚ Ð² [Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ñƒ] Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¸Ð¼ÐµÐ½Ð½Ð¾ ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð².
"""


class AIChatHandler:
    """Handles incoming chat messages with AI-powered responses."""

    def __init__(
        self,
        *,
        llm: LLMProvider,
        catalog: ProductCatalog,
        storage: Storage,
    ):
        self.gpt = llm
        self.catalog = catalog
        self.storage = storage
        self._system_prompt_cache: Optional[str] = None
        self._system_prompt_product_count: int = 0

    def _get_system_prompt(self) -> str:
        """Build system prompt with current catalog data (cached)."""
        current_count = len(self.catalog.products)
        if self._system_prompt_cache is None or self._system_prompt_product_count != current_count:
            summary = self.catalog.build_catalog_summary()
            self._system_prompt_cache = SYSTEM_PROMPT.format(catalog_summary=summary)
            self._system_prompt_product_count = current_count
            log.info("system_prompt_rebuilt", extra={"product_count": current_count, "prompt_length": len(self._system_prompt_cache)})
        return self._system_prompt_cache

    def invalidate_system_prompt_cache(self) -> None:
        """Force rebuild of system prompt (after catalog update)."""
        self._system_prompt_cache = None

    # --- Intent detection (lightweight, before GPT) ---

    @staticmethod
    def detect_operator_request(text: str) -> bool:
        """Check if the user wants to talk to a human operator."""
        lower = text.lower().strip()
        operator_keywords = [
            "Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€", "operator", "Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€", "Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº",
            "Ð¿Ð¾Ð·Ð¾Ð²Ð¸Ñ‚Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°", "Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð° Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°",
            "Ð¶Ð¸Ð²Ð¾Ð¹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€", "ÑÐ²ÑÐ·Ð°Ñ‚ÑŒÑÑ Ñ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼",
            "Ñ…Ð¾Ñ‡Ñƒ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°", "Ð½ÑƒÐ¶ÐµÐ½ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€",
        ]
        return any(kw in lower for kw in operator_keywords)

    @staticmethod
    def detect_product_search(text: str) -> Optional[str]:
        """Try to extract a product search query from the message.

        Returns the search query string if it looks like a product search, None otherwise.
        """
        lower = text.lower().strip()
        # Explicit search patterns
        search_patterns = [
            r"(?:Ð½Ð°Ð¹Ð´Ð¸|Ð¿Ð¾ÐºÐ°Ð¶Ð¸|Ð¸Ñ‰Ñƒ|Ð¿Ð¾Ð¸Ñ‰Ð¸|ÐµÑÑ‚ÑŒ Ð»Ð¸|ÐµÑÑ‚ÑŒ|Ð² Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸)\s+(.+)",
            r"(?:Ñ…Ð¾Ñ‡Ñƒ|Ñ…Ð¾Ñ‚ÐµÐ» Ð±Ñ‹|Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÐµÑ‚|Ð½ÑƒÐ¶Ð½[Ð°Ñ‹]?)\s+(.+)",
            r"(?:ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ð¸Ñ‚|Ñ†ÐµÐ½Ð°|Ð¿Ð¾Ñ‡Ñ‘Ð¼|Ð¿Ð¾Ñ‡ÐµÐ¼)\s+(.+)",
            r"(?:Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð¿Ñ€Ð¾|Ñ‡Ñ‚Ð¾ Ð·Ð°|Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ)\s+(.+)",
        ]
        for pattern in search_patterns:
            m = re.search(pattern, lower)
            if m:
                return m.group(1).strip()
        return None

    # --- Conversation history ---

    async def _get_history(self, dialog_id: str) -> List[Dict[str, str]]:
        """Retrieve conversation history from Redis."""
        return await self.storage.get_chat_history(dialog_id, limit=MAX_HISTORY_MESSAGES)

    async def _save_message(self, dialog_id: str, role: str, text: str) -> None:
        """Save a message to conversation history in Redis."""
        await self.storage.append_chat_message(dialog_id, role, text)

    # --- Main handler ---

    async def handle_message(
        self,
        dialog_id: str,
        user_text: str,
    ) -> Tuple[str, bool]:
        """Process a user message and generate a response.

        Returns:
            (response_text, transfer_to_operator)
        """
        # 1. Check for operator transfer request
        if self.detect_operator_request(user_text):
            return ("ÐŸÐµÑ€ÐµÐ²Ð¾Ð¶Ñƒ Ð²Ð°Ñ Ð½Ð° Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ... ðŸ‘¤", True)

        # 2. Search for relevant products to enrich the GPT context
        search_query = self.detect_product_search(user_text)
        product_context = ""

        if search_query:
            found = self.catalog.search(search_query, limit=MAX_SEARCH_RESULTS_FOR_GPT)
            if found:
                product_context = self._format_search_results(found)
        else:
            # Even without explicit search, try finding products mentioned in the text
            found = self.catalog.search(user_text, limit=5)
            if found:
                product_context = self._format_search_results(found)

        # 3. Build messages for GPT
        system_prompt = self._get_system_prompt()

        messages: List[Dict[str, str]] = [
            {"role": "system", "text": system_prompt},
        ]

        # Add conversation history
        history = await self._get_history(dialog_id)
        messages.extend(history)

        # Add product search context if found
        user_message = user_text
        if product_context:
            user_message = (
                f"{user_text}\n\n"
                f"[Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ñƒ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÑ‚Ñƒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ðµ]:\n"
                f"{product_context}"
            )

        messages.append({"role": "user", "text": user_message})

        # 4. Call LLM
        try:
            reply = await self.gpt.completion(messages)
        except LLMError as e:
            log.error("ai_chat_llm_error", extra={"dialog_id": dialog_id, "error": str(e)})
            reply = (
                "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°. "
                "ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ñ‘ Ñ€Ð°Ð· Ð¸Ð»Ð¸ Ð½Ð°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ Â«Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Â» Ð´Ð»Ñ ÑÐ²ÑÐ·Ð¸ Ñ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð¾Ð¼."
            )

        # 4b. Strip Markdown â€” GPT may still produce it despite the prompt
        reply = _strip_markdown(reply)

        # 5. Save messages to history
        await self._save_message(dialog_id, "user", user_text)
        await self._save_message(dialog_id, "assistant", reply)

        return (reply, False)

    def _format_search_results(self, products: List[Dict[str, Any]]) -> str:
        """Format product search results for inclusion in GPT context."""
        lines: List[str] = []
        for p in products:
            parts = [p.get("title", "?")]
            if p.get("price"):
                price_str = f"{p['price']}â‚½"
                if p.get("priceold"):
                    price_str += f" (Ð±Ñ‹Ð»Ð¾ {p['priceold']}â‚½)"
                parts.append(price_str)
            if p.get("portion"):
                parts.append(str(p["portion"]))
            qty = p.get("quantity", "")
            if qty == "0":
                parts.append("Ð½ÐµÑ‚ Ð² Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸")
            else:
                parts.append("Ð² Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸")
            if p.get("url"):
                url = p["url"]
                if not url.startswith("http"):
                    url = f"https://myryba.ru{url}"
                parts.append(url)
            if p.get("characteristics"):
                chars = "; ".join(f"{c['title']}: {c['value']}" for c in p["characteristics"] if c.get("title"))
                if chars:
                    parts.append(f"({chars})")
            lines.append(" | ".join(parts))
        return "\n".join(lines)
